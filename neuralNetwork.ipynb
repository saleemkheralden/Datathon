{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-11 02:14:58.071169: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-11 02:14:58.071208: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor as dtr\n",
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "from sklearn.ensemble import GradientBoostingRegressor as gbr\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "url = 'https://drive.google.com/file/d/1-4YpXkd2kIOM5viSRw8g7oOQm8sicciB/view?usp=sharing'\n",
    "url = 'https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
    "y_train = pd.read_csv(url, index_col=0)\n",
    "\n",
    "url = 'https://drive.google.com/file/d/1-7VK3dNry2-AYnfRsxMWsOKhHHMTN_ZA/view?usp=sharing'\n",
    "url = 'https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
    "test_indices = pd.read_csv(url, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def month_to_season(month: int):\n",
    "    if month < 4:\n",
    "        return \"winter\"\n",
    "    elif month < 7:\n",
    "        return \"spring\"\n",
    "    elif month < 10:\n",
    "        return \"summer\"\n",
    "    elif month < 13:\n",
    "        return \"fall\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"weather.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "df[\"timestamp\"] = df[[\"timestamp\"]].apply(lambda x: f\"{x[0][0:4]}-{x[0][4:6]}-{x[0][6:8]}\", axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# df[[\"timestamp\"]].apply(lambda x: f\"{x[0][0:4]}-{x[0][4:6]}-{x[0][6:8]}\", axis=1)\n",
    "df = df.groupby(\"timestamp\").mean()\n",
    "df = df[df.index >= \"2009-12-28\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "fitted_df = pd.DataFrame(df.iloc[0:7].sum() / 7, columns=[f\"{df.index[0]}/{df.index[6]}\"]).transpose()\n",
    "for i in range(7, len(df.index), 7):\n",
    "    fitted_df = pd.concat([fitted_df, pd.DataFrame(df.iloc[i:i + 7].sum() / 7, columns=[f\"{df.index[i]}/{df.index[i + 6]}\"]).transpose()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "fitted_df.index.name=\"year_weeks\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "y_train = pd.concat([y_train, fitted_df.iloc[0:len(y_train.index)]], axis=1)\n",
    "y_train.index.name = \"year_weeks\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "train = y_train.reset_index()\n",
    "melted_train = pd.melt(train, id_vars=[\"year_weeks\", \"Temperature\", \"Relative Humidity\", \"Wind Speed\", \"Wind Direction\"], var_name=\"City\", value_name=\"Weight\")\n",
    "melted_train[\"temp\"] = melted_train[[\"City\"]].apply(lambda x: x[0].split(\"_\"), axis=1)\n",
    "melted_train[[\"food\", \"district\"]] = pd.DataFrame(melted_train[\"temp\"].tolist())\n",
    "\n",
    "melted_train[\"month\"] = list(map(lambda x: int(x.split(\"/\")[1].split(\"-\")[1]), melted_train.year_weeks))\n",
    "melted_train[\"day\"] = list(map(lambda x: int(x.split(\"/\")[1].split(\"-\")[2]), melted_train.year_weeks))\n",
    "melted_train[\"season\"] = list(map(lambda x: month_to_season(x), melted_train.month))\n",
    "\n",
    "melted_train = melted_train[[\"year_weeks\", \"month\", \"day\", \"season\", \"year_weeks\", \"Temperature\",\n",
    "                             \"Relative Humidity\", \"Wind Speed\", \"Wind Direction\", \"food\", \"district\", \"Weight\"]]\n",
    "\n",
    "X_train_df = pd.concat([pd.get_dummies(melted_train[\"month\"]),\n",
    "                        # pd.get_dummies(melted_train[\"day\"]),\n",
    "                        # pd.get_dummies(melted_train[\"season\"]),\n",
    "                        # melted_train[\"Temperature\"],\n",
    "                        # melted_train[\"Relative Humidity\"],\n",
    "                        # melted_train[\"Wind Speed\"],\n",
    "                        # melted_train[\"Wind Direction\"],\n",
    "                        pd.get_dummies(melted_train[\"food\"]),\n",
    "                        pd.get_dummies(melted_train[\"district\"])], axis=1)\n",
    "\n",
    "X_train = X_train_df.to_numpy()\n",
    "Y_train = melted_train[\"Weight\"].to_numpy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "ddd = pd.DataFrame(y_train.sum(), columns=[\"sum\"])\n",
    "zeros = ddd[ddd[\"sum\"] == 0].index.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_61 (Dense)            (None, 128)               6016      \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 500001)            64500129  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,506,145\n",
      "Trainable params: 64,506,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      " 730/3079 [======>.......................] - ETA: 19:13 - loss: 2.8727 - accuracy: 0.8643"
     ]
    }
   ],
   "source": [
    "X_train_08, X_test_02, Y_train_08, Y_test_02 = train_test_split(X_train, Y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # tf.keras.layers.Flatten(input_shape=(46, 1))\n",
    "    tf.keras.layers.Dense(128, input_shape=(46,), activation=\"relu\"),\n",
    "    # tf.keras.layers.Dense(128, activation='relu'),\n",
    "    # tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(500001 , activation='softmax')\n",
    "])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=5)\n",
    "# model.evaluate(X_test_02, Y_test_02)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}